{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "sys.path.append(module_path)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from keras import backend as K\n",
    "from common import distance, functions\n",
    "from models import Facenet\n",
    "from detectors import FaceDetector\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"../data/FaceData/\"\n",
    "path_haar = \"../data/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "\n",
    "def read_image(index):\n",
    "    path = os.path.join(ROOT, index[0], index[1])\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (160, 160))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(directory, split=0.9):\n",
    "    folders = os.listdir(directory)\n",
    "    num_train = int(len(folders) * split)\n",
    "\n",
    "    random.shuffle(folders)\n",
    "\n",
    "    train_list, test_list = {}, {}\n",
    "\n",
    "    # Creating Train-list\n",
    "    for folder in folders[:num_train]:\n",
    "        num_files = len(os.listdir(os.path.join(directory, folder)))\n",
    "        train_list[folder] = num_files\n",
    "\n",
    "    # Creating Test-list\n",
    "    for folder in folders[num_train:]:\n",
    "        num_files = len(os.listdir(os.path.join(directory, folder)))\n",
    "        test_list[folder] = num_files\n",
    "\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "train_list, test_list = split_dataset(ROOT, split=0.9)\n",
    "print(\"Length of training list:\", len(train_list))\n",
    "print(\"Length of testing list :\", len(test_list))\n",
    "\n",
    "# train_list, test list contains the folder names along with the number of files in the folder.\n",
    "print(\"\\nTest List:\", test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triplets(directory, folder_list, max_files=10):\n",
    "    triplets = []\n",
    "    folders = list(folder_list.keys())\n",
    "\n",
    "    for folder in folders:\n",
    "        path = os.path.join(directory, folder)\n",
    "        files = list(os.listdir(path))[:max_files]\n",
    "        num_files = len(files)\n",
    "\n",
    "        for i in range(num_files - 1):\n",
    "            for j in range(i + 1, num_files):\n",
    "                anchor = (folder, f\"{files[i]}\")\n",
    "                positive = (folder, f\"{files[j]}\")\n",
    "\n",
    "                neg_folder = folder\n",
    "                while neg_folder == folder:\n",
    "                    neg_folder = random.choice(folders)\n",
    "                neg_file = random.choice(\n",
    "                    os.listdir(os.path.join(directory, neg_folder))\n",
    "                )\n",
    "                negative = (neg_folder, f\"{neg_file}\")\n",
    "\n",
    "                triplets.append((anchor, positive, negative))\n",
    "\n",
    "    random.shuffle(triplets)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplet = create_triplets(ROOT, train_list)\n",
    "test_triplet = create_triplets(ROOT, test_list)\n",
    "\n",
    "print(\"Number of training triplets:\", len(train_triplet))\n",
    "print(\"Number of testing triplets :\", len(test_triplet))\n",
    "\n",
    "print(\"\\nExamples of triplets:\")\n",
    "for i in range(5):\n",
    "    print(train_triplet[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(triplet_list, batch_size=256, preprocess=True):\n",
    "    while True:\n",
    "        i = 0\n",
    "        anchor = []\n",
    "        positive = []\n",
    "        negative = []\n",
    "\n",
    "        while i < batch_size:\n",
    "            a, p, n = random.choice(triplet_list)\n",
    "\n",
    "            anc_img = np.array(read_image(a))\n",
    "            pos_img = np.array(read_image(p))\n",
    "            neg_img = np.array(read_image(n))\n",
    "\n",
    "            if preprocess:\n",
    "                anc_img = preprocess_input(anc_img)\n",
    "                pos_img = preprocess_input(pos_img)\n",
    "                neg_img = preprocess_input(neg_img)\n",
    "\n",
    "            anchor.append(anc_img)\n",
    "            positive.append(pos_img)\n",
    "            negative.append(neg_img)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        yield (\n",
    "            [np.array(anchor), np.array(positive), np.array(negative)],\n",
    "            np.zeros((batch_size, 1)).astype(\"float32\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = 6\n",
    "\n",
    "f, axes = plt.subplots(num_plots, 3, figsize=(15, 20))\n",
    "\n",
    "for x in get_batch(train_triplet, batch_size=num_plots, preprocess=False):\n",
    "    a, p, n = x[0][0], x[0][1], x[0][2]\n",
    "    for i in range(num_plots):\n",
    "        axes[i, 0].imshow(a[i])\n",
    "        axes[i, 1].imshow(p[i])\n",
    "        axes[i, 2].imshow(n[i])\n",
    "        i += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss_t(y_true, y_pred):\n",
    "    anchor = y_pred[:, 0:128]\n",
    "    pos = y_pred[:, 128:256]\n",
    "    neg = y_pred[:, 256:384]\n",
    "\n",
    "    positive_distance = K.sum(K.abs(anchor - pos), axis=1)\n",
    "    negative_distance = K.sum(K.abs(anchor - neg), axis=1)\n",
    "\n",
    "    # Concatenate positive_distance and negative_distance along a new axis\n",
    "    distances = K.stack([positive_distance, negative_distance], axis=1)\n",
    "\n",
    "    # Apply softmax to the concatenated tensor along axis 1\n",
    "    probs = K.softmax(distances, axis=1)\n",
    "\n",
    "    # Calculate the loss using the probabilities\n",
    "    loss = K.mean(K.abs(probs[:, 0]) + K.abs(1.0 - probs[:, 1]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = Facenet.loadModel()\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "fine_tune_at = 355\n",
    "for layer in pretrained_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = pretrained_model.get_layer(\"Dropout\")\n",
    "last_output = last_layer.output\n",
    "# Bottleneck\n",
    "x = tf.keras.layers.Dense(256, use_bias=False, name=\"Bottleneck\")(last_output)\n",
    "x = tf.keras.layers.BatchNormalization(\n",
    "    momentum=0.995, epsilon=0.001, scale=False, name=\"Bottleneck_BatchNorm\"\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.models.Model(pretrained_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model_a = tf.keras.layers.Input((160, 160, 3))\n",
    "triplet_model_n = tf.keras.layers.Input((160, 160, 3))\n",
    "triplet_model_p = tf.keras.layers.Input((160, 160, 3))\n",
    "triplet_model_out = tf.keras.layers.Concatenate()(\n",
    "    [model(triplet_model_a), model(triplet_model_p), model(triplet_model_n)]\n",
    ")\n",
    "triplet_model = tf.keras.models.Model(\n",
    "    [triplet_model_a, triplet_model_p, triplet_model_n], triplet_model_out\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=triplet_loss_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = triplet_model.fit(get_batch(train_triplet), validation_data=get_batch(test_triplet), steps_per_epoch=100, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.save(\"triplet_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
