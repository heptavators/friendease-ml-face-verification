{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "sys.path.append(module_path)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from keras import backend as K\n",
    "from common import distance, functions\n",
    "from models import Facenet\n",
    "from detectors import FaceDetector\n",
    "from tensorflow.keras.applications import resnet\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"../data/FaceData/\"\n",
    "path_haar = \"../data/haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename):\n",
    "    \"\"\"\n",
    "    Load the specified file as a JPEG image, preprocess it and\n",
    "    resize it to the target shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (160, 160))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_triplets(anchor, positive, negative):\n",
    "    \"\"\"\n",
    "    Given the filenames corresponding to the three images, load and\n",
    "    preprocess them.\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        preprocess_image(anchor),\n",
    "        preprocess_image(positive),\n",
    "        preprocess_image(negative),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(directory, split=0.9):\n",
    "    folders = os.listdir(directory)\n",
    "    num_train = int(len(folders) * split)\n",
    "\n",
    "    random.shuffle(folders)\n",
    "\n",
    "    train_list, test_list = {}, {}\n",
    "\n",
    "    # Creating Train-list\n",
    "    for folder in folders[:num_train]:\n",
    "        num_files = len(os.listdir(os.path.join(directory, folder)))\n",
    "        train_list[folder] = num_files\n",
    "\n",
    "    # Creating Test-list\n",
    "    for folder in folders[num_train:]:\n",
    "        num_files = len(os.listdir(os.path.join(directory, folder)))\n",
    "        test_list[folder] = num_files\n",
    "\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "train_list, test_list = split_dataset(ROOT, split=1.0)\n",
    "print(\"Length of training list:\", len(train_list))\n",
    "print(\"Length of testing list :\", len(test_list))\n",
    "\n",
    "# train_list, test list contains the folder names along with the number of files in the folder.\n",
    "print(\"\\nTest List:\", test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triplets(directory, folder_list, max_files=10):\n",
    "    anchors = []\n",
    "    positives = []\n",
    "    negatives = []\n",
    "    folders = list(folder_list.keys())\n",
    "\n",
    "    for folder in folders:\n",
    "        path = os.path.join(directory, folder)\n",
    "        files = list(os.listdir(path))[:max_files]\n",
    "        num_files = len(files)\n",
    "\n",
    "        for i in range(num_files - 1):\n",
    "            for j in range(i + 1, num_files):\n",
    "                anchor = os.path.join(ROOT, folder, files[i])\n",
    "                positive = os.path.join(ROOT, folder, files[j])\n",
    "\n",
    "                neg_folder = folder\n",
    "                while neg_folder == folder:\n",
    "                    neg_folder = random.choice(folders)\n",
    "                neg_file = random.choice(\n",
    "                    os.listdir(os.path.join(directory, neg_folder))\n",
    "                )\n",
    "                negative = os.path.join(ROOT, neg_folder, neg_file)\n",
    "\n",
    "                anchors.append(anchor)\n",
    "                positives.append(positive)\n",
    "                negatives.append(negative)\n",
    "\n",
    "    return anchors, positives, negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors, positives, negatives = create_triplets(ROOT, train_list)\n",
    "\n",
    "print(\"Number of training triplets:\", len(anchors))\n",
    "\n",
    "print(\"\\nExamples of triplets:\")\n",
    "for i in range(5):\n",
    "    print(f'{anchors[i]} {positives[i]} {negatives[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_dataset = tf.data.Dataset.from_tensor_slices(anchors)\n",
    "positive_dataset = tf.data.Dataset.from_tensor_slices(positives)\n",
    "negative_dataset = tf.data.Dataset.from_tensor_slices(negatives)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.map(preprocess_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(anchors)\n",
    "train_dataset = dataset.take(round(image_count * 0.9))\n",
    "val_dataset = dataset.skip(round(image_count * 0.9))\n",
    "\n",
    "train_dataset = train_dataset.batch(1024, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_dataset.batch(512, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(anchor, positive, negative):\n",
    "    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
    "\n",
    "    def show(ax, image):\n",
    "        ax.imshow(image)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "    axs = fig.subplots(3, 3)\n",
    "    for i in range(3):\n",
    "        show(axs[i, 0], anchor[i])\n",
    "        show(axs[i, 1], positive[i])\n",
    "        show(axs[i, 2], negative[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(*list(train_dataset.take(1).as_numpy_iterator())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder():\n",
    "    pretrained_model = Facenet.loadModel()\n",
    "    pretrained_model.trainable = True\n",
    "    fine_tune_at = 355\n",
    "\n",
    "    for layer in pretrained_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    last_layer = pretrained_model.get_layer(\"Dropout\")\n",
    "    last_output = last_layer.output\n",
    "    # Bottleneck\n",
    "    x = tf.keras.layers.Dense(256, use_bias=False, name=\"Bottleneck\")(last_output)\n",
    "    x = tf.keras.layers.BatchNormalization(\n",
    "        momentum=0.995, epsilon=0.001, scale=False, name=\"Bottleneck_BatchNorm\"\n",
    "    )(x)\n",
    "\n",
    "    model = tf.keras.models.Model(pretrained_model.input, x, name=\"Facenet_Model\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_encoder()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_input = tf.keras.layers.Input((160, 160, 3), name=\"Anchor_Input\")\n",
    "positive_input = tf.keras.layers.Input((160, 160, 3), name=\"Positive_Input\")\n",
    "negative_input = tf.keras.layers.Input((160, 160, 3), name=\"Negative_Input\")\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    model(resnet.preprocess_input(anchor_input)),\n",
    "    model(resnet.preprocess_input(positive_input)),\n",
    "    model(resnet.preprocess_input(negative_input)),\n",
    ")\n",
    "\n",
    "siamese_network = tf.keras.Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input],\n",
    "    outputs=distances,\n",
    "    name=\"Siamese_Network\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(tf.keras.Model):\n",
    "    # Builds a Siamese model based on a base-model\n",
    "    def __init__(self, siamese_network, margin=1.0):\n",
    "        super(SiameseModel, self).__init__()\n",
    "\n",
    "        self.margin = margin\n",
    "        self.siamese_network = siamese_network\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape get the gradients when we compute loss, and uses them to update the weights\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # Get the two distances from the network, then compute the triplet loss\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics so the reset_states() can be called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = siamese_model.fit(train_dataset, epochs=150, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.save_weights(\"siamese_model-final\")\n",
    "siamese_model.save(\"siamese_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_encoder(model):\n",
    "    encoder = get_encoder()\n",
    "    i = 0\n",
    "    for e_layer in model.layers[0].layers[3].layers:\n",
    "        layer_weight = e_layer.get_weights()\n",
    "        encoder.layers[i].set_weights(layer_weight)\n",
    "        i += 1\n",
    "    return encoder\n",
    "\n",
    "encoder = extract_encoder(siamese_model)\n",
    "encoder.save_weights(\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(face_list1, face_list2, threshold=1.3):\n",
    "    # Getting the encodings for the passed faces\n",
    "    tensor1 = encoder.predict(face_list1)\n",
    "    tensor2 = encoder.predict(face_list2)\n",
    "\n",
    "    distance = np.sum(np.square(tensor1 - tensor2), axis=-1)\n",
    "    prediction = np.where(distance <= threshold, 0, 1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelMetrics(pos_list, neg_list):\n",
    "    true = np.array([0] * len(pos_list) + [1] * len(neg_list))\n",
    "    pred = np.append(pos_list, neg_list)\n",
    "\n",
    "    # Compute and print the accuracy\n",
    "    print(f\"\\nAccuracy of model: {accuracy_score(true, pred)}\\n\")\n",
    "\n",
    "    # Compute and plot the Confusion matrix\n",
    "    cf_matrix = confusion_matrix(true, pred)\n",
    "\n",
    "    categories = [\"Similar\", \"Different\"]\n",
    "    names = [\"True Similar\", \"False Similar\", \"False Different\", \"True Different\"]\n",
    "    percentages = [\n",
    "        \"{0:.2%}\".format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)\n",
    "    ]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(names, percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "\n",
    "    sns.heatmap(\n",
    "        cf_matrix,\n",
    "        annot=labels,\n",
    "        cmap=\"Blues\",\n",
    "        fmt=\"\",\n",
    "        xticklabels=categories,\n",
    "        yticklabels=categories,\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Predicted\", fontdict={\"size\": 14}, labelpad=10)\n",
    "    plt.ylabel(\"Actual\", fontdict={\"size\": 14}, labelpad=10)\n",
    "    plt.title(\"Confusion Matrix\", fontdict={\"size\": 18}, pad=20)\n",
    "\n",
    "\n",
    "pos_list = np.array([])\n",
    "neg_list = np.array([])\n",
    "\n",
    "for data in val_dataset:\n",
    "    a, p, n = data\n",
    "    pos_list = np.append(pos_list, classify_images(a, p))\n",
    "    neg_list = np.append(neg_list, classify_images(a, n))\n",
    "    break\n",
    "\n",
    "ModelMetrics(pos_list, neg_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
